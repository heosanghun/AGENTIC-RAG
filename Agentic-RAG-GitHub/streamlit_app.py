"""
Agentic RAG ì§€ëŠ¥í˜• ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œ - Streamlit ì›¹ ì¸í„°í˜ì´ìŠ¤
"""
import streamlit as st
import os
import sys
from pathlib import Path
import time
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["OPENAI_API_KEY"] = "your_openai_api_key_here"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="Agentic RAG ì‹œìŠ¤í…œ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .sub-header {
        font-size: 1.5rem;
        color: #ff7f0e;
        margin-bottom: 1rem;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 1rem;
        border-left: 4px solid;
    }
    .user-message {
        background-color: #e3f2fd;
        border-left-color: #2196f3;
    }
    .assistant-message {
        background-color: #f3e5f5;
        border-left-color: #9c27b0;
    }
    .system-message {
        background-color: #fff3e0;
        border-left-color: #ff9800;
    }
    .status-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #ddd;
        margin: 1rem 0;
    }
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #ddd;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .answer-container {
        background-color: #f8f9fa;
        border: 2px solid #e9ecef;
        border-radius: 15px;
        padding: 2rem;
        margin: 2rem 0;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    .answer-header {
        font-size: 1.3rem;
        font-weight: bold;
        color: #495057;
        margin-bottom: 1rem;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #dee2e6;
    }
    .answer-content {
        font-size: 1.1rem;
        line-height: 1.6;
        color: #212529;
    }
    .metadata-box {
        background-color: #e9ecef;
        border-radius: 8px;
        padding: 1rem;
        margin-top: 1rem;
        font-size: 0.9rem;
        color: #6c757d;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def initialize_system():
    """ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ê³  ì›Œí¬í”Œë¡œìš°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        from workflow_graph import AgenticRAGWorkflow
        from data_pipeline import DataPipeline
        
        with st.spinner("ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘..."):
            # ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
            pipeline = DataPipeline()
            pipeline.build_pipeline()
            
            # ì›Œí¬í”Œë¡œìš° ìƒì„±
            workflow = AgenticRAGWorkflow(pipeline)
            workflow.build_workflow()
            
        st.success("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        return workflow
    except Exception as e:
        st.error(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None

def display_chat_history():
    """ì±„íŒ… ê¸°ë¡ì„ í‘œì‹œí•©ë‹ˆë‹¤."""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
            # ë©”íƒ€ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œ
            if "metadata" in message and message["metadata"]:
                with st.expander("ğŸ“Š ë©”íƒ€ë°ì´í„°"):
                    st.json(message["metadata"])

def add_message(role, content, metadata=None):
    """ë©”ì‹œì§€ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€í•©ë‹ˆë‹¤."""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    st.session_state.messages.append({
        "role": role,
        "content": content,
        "timestamp": datetime.now(),
        "metadata": metadata
    })

def process_question(workflow, question):
    """ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        with st.spinner(" ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³  ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            results = workflow.run_workflow(question)
            
            # ê²°ê³¼ ì²˜ë¦¬
            if results:
                # ë§ˆì§€ë§‰ ê²°ê³¼ì—ì„œ ë‹µë³€ ì¶”ì¶œ
                last_result = results[-1]
                if isinstance(last_result, tuple) and len(last_result) == 2:
                    node_name, result_data = last_result
                    
                    # ë©”ì‹œì§€ì—ì„œ ë‹µë³€ ì¶”ì¶œ
                    if "messages" in result_data and result_data["messages"]:
                        answer = result_data["messages"][-1].content
                        
                        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                        metadata = {
                            "node_name": node_name,
                            "total_nodes": len(results),
                            "processing_time": time.time(),
                            "workflow_path": [r[0] for r in results]
                        }
                        
                        return answer, metadata
            
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", {"error": "No response generated"}
            
    except Exception as e:
        st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", {"error": str(e)}

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜"""
    
    # í—¤ë”
    st.markdown('<h1 class="main-header">ğŸ¤– Agentic RAG ì§€ëŠ¥í˜• ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œ</h1>', unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.markdown("## ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ì‹œìŠ¤í…œ ì´ˆê¸°í™”", type="primary"):
            st.session_state.workflow = initialize_system()
        
        # ì‹œìŠ¤í…œ ì •ë³´
        if "workflow" in st.session_state and st.session_state.workflow:
            st.success("âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ë¨")
        else:
            st.warning("âš ï¸ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ê°„ë‹¨í•œ ì‚¬ìš©ë²•
        st.markdown("## ğŸ“– ì‚¬ìš©ë²•")
        st.markdown("""
        1. **ì‹œìŠ¤í…œ ì´ˆê¸°í™”** ë²„íŠ¼ í´ë¦­
        2. ì§ˆë¬¸ ì…ë ¥ì°½ì— ì§ˆë¬¸ ì…ë ¥
        3. ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ í™œìš©
        4. AI ë‹µë³€ í™•ì¸
        """)
        
        # ë²„ì „ ì •ë³´
        st.markdown("## â„¹ï¸ ë²„ì „ ì •ë³´")
        st.markdown("**Agentic RAG v1.0**")
        st.markdown("LangGraph + OpenAI GPT-4")
    
    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown('<h2 class="sub-header">ğŸ’¬ ì§ˆë¬¸í•˜ê¸°</h2>', unsafe_allow_html=True)
        
        # ì§ˆë¬¸ ì…ë ¥
        question = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...")
        
        if question:
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            add_message("user", question)
            
            # ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°
            if "workflow" not in st.session_state or not st.session_state.workflow:
                st.error("âš ï¸ ì‹œìŠ¤í…œì„ ë¨¼ì € ì´ˆê¸°í™”í•´ì£¼ì„¸ìš”. ì‚¬ì´ë“œë°”ì˜ 'ì‹œìŠ¤í…œ ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
                return
            
            # ì§ˆë¬¸ ì²˜ë¦¬
            answer, metadata = process_question(st.session_state.workflow, question)
            
            # ë‹µë³€ ë©”ì‹œì§€ ì¶”ê°€
            add_message("assistant", answer, metadata)
            
            # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            st.rerun()
        
        # ì˜ˆì‹œ ì§ˆë¬¸ (ì§ˆë¬¸ ì…ë ¥ì°½ ë°”ë¡œ ì•„ë˜)
        st.markdown('<h3 class="sub-header">ğŸ“‹ ì˜ˆì‹œ ì§ˆë¬¸</h3>', unsafe_allow_html=True)
        
        example_questions = [
            "agentic ragê°€ ì–´ë–¤ ì˜ë¯¸ì•¼?",
            "ê¸ˆìœµ ì‹œì¥ì˜ ìµœì‹  ë™í–¥ì€?",
            "íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ë°©ë²•ì€?",
            "ì£¼ì‹ ì‹œì¥ ë¶„ì„ ë°©ë²•ì€?",
            "ì•”í˜¸í™”í íˆ¬ì ì „ëµì€?",
            "ë¶€ë™ì‚° íˆ¬ì ì‹œ ê³ ë ¤ì‚¬í•­ì€?",
            "ì€í‡´ ê³„íš ìˆ˜ë¦½ ë°©ë²•ì€?",
            "ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì „ëµì€?"
        ]
        
        # 2ì—´ë¡œ ì˜ˆì‹œ ì§ˆë¬¸ ë°°ì¹˜
        cols = st.columns(2)
        for i, example in enumerate(example_questions):
            col_idx = i % 2
            with cols[col_idx]:
                if st.button(f"ğŸ’¡ {example[:25]}...", key=f"example_{i}", use_container_width=True):
                    st.session_state.example_question = example
                    st.rerun()
        
        # ë‹µë³€ í‘œì‹œ ì˜ì—­ (ë¹¨ê°„ìƒ‰ ê°€ì´ë“œì„  ì˜ì—­)
        if "messages" in st.session_state and st.session_state.messages:
            # ë§ˆì§€ë§‰ ë‹µë³€ë§Œ í‘œì‹œ
            last_message = st.session_state.messages[-1]
            if last_message["role"] == "assistant":
                st.markdown('<div class="answer-container">', unsafe_allow_html=True)
                st.markdown('<div class="answer-header">ğŸ¤– AI ë‹µë³€</div>', unsafe_allow_html=True)
                st.markdown(f'<div class="answer-content">{last_message["content"]}</div>', unsafe_allow_html=True)
                
                # ë©”íƒ€ë°ì´í„° í‘œì‹œ
                if "metadata" in last_message and last_message["metadata"]:
                    with st.expander("ğŸ“Š ì²˜ë¦¬ ì •ë³´"):
                        st.json(last_message["metadata"])
                
                st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<h2 class="sub-header">ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´</h2>', unsafe_allow_html=True)
        
        # ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´
        if "workflow" in st.session_state and st.session_state.workflow:
            st.success("âœ… ì‹œìŠ¤í…œ ì¤€ë¹„ë¨")
            
            # ì›Œí¬í”Œë¡œìš° ì •ë³´
            with st.expander("ğŸ”§ ì›Œí¬í”Œë¡œìš° ì •ë³´"):
                try:
                    mermaid_diagram = st.session_state.workflow.visualize_graph()
                    if mermaid_diagram:
                        st.code(mermaid_diagram, language="mermaid")
                except:
                    st.info("ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # í†µê³„
        if "messages" in st.session_state:
            st.markdown("## ğŸ“ˆ í†µê³„")
            st.metric("ì´ ëŒ€í™” ìˆ˜", len(st.session_state.messages))
            
            user_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
            st.metric("ì‚¬ìš©ì ì§ˆë¬¸", user_messages)
            
            assistant_messages = len([m for m in st.session_state.messages if m["role"] == "assistant"])
            st.metric("ì‹œìŠ¤í…œ ë‹µë³€", assistant_messages)

if __name__ == "__main__":
    main()
