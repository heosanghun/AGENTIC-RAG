안녕하세요. 보내주신 이미지를 모두 분석하여 Agentic RAG를 이용한 지능형 정보 검색 시스템 개발 단계를 상세히 안내해 드리겠습니다.이 내용은 LangGraph와 Agentic RAG를 활용하여, 사용자의 질문을 받으면 관련된 문서를 검색하고(Retrieve), 그 관련성을 평가하여 필요에 따라 질문을 재작성(Rewrite)하거나 최종 답변을 생성(Generate)하는 지능형 정보 검색 시스템을 구축하는 과정입니다.전체적인 흐름은 다음과 같습니다:시작(Start): 사용자가 질문을 입력합니다.에이전트(Agent): 질문을 받아 어떤 도구(Tool)를 사용할지 결정합니다.도구(Tools): 검색 도구를 사용해 정보를 가져옵니다(Retrieve).검색 결과 평가: 검색된 정보가 사용자의 질문과 관련성이 있는지 평가합니다.분기:관련성 높음: 검색된 정보를 바탕으로 최종 답변을 생성합니다(Generate).관련성 낮음: 더 나은 검색 결과를 얻기 위해 사용자의 질문을 재작성합니다(Rewrite). 재작성된 질문으로 다시 에이전트 단계로 돌아갑니다.종료(End): 최종 답변이 사용자에게 전달되면 프로세스가 종료됩니다.아래의 단계별 가이드를 따라 직접 개발을 진행해 보세요.개발 단계별 상세 안내1단계: 기본 환경 설정 및 라이브러리 설치가장 먼저 필요한 라이브러리를 설치하고, OpenAI API 키를 설정하여 환경을 구성합니다..env 파일 생성: 프로젝트 루트 디렉토리에 .env 파일을 만들고 그 안에 아래와 같이 OpenAI API 키를 추가합니다. code Codedownloadcontent_copyexpand_less    OPENAI_API_KEY="sk-..."
  라이브러리 설치: 터미널 또는 명령 프롬프트에서 다음 라이브러리들을 설치합니다. code Bashdownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    pip install langchain langgraph langchain_openai python-dotenv beautifulsoup4 chromadb tiktoken
  API 키 로드: 파이썬 스크립트(.py) 또는 주피터 노트북(.ipynb)에서 다음 코드를 실행하여 API 키를 환경 변수로 로드합니다.langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    import os
from dotenv import load_dotenv

# .env 파일에서 환경 변수를 로드합니다.
load_dotenv()

# 환경 변수에서 OpenAI API 키를 가져옵니다.
openai_api_key = os.getenv("OPENAI_API_KEY")
os.environ["OPENAI_API_KEY"] = openai_api_key

# API 키가 존재하지 않는 경우 에러를 발생시킵니다.
if not openai_api_key:
    raise ValueError("OpenAI API 키가 없습니다. 한 번 더 확인 부탁드립니다.")
  2단계: 데이터 크롤링 및 벡터 스토어 생성금융 정보를 제공하는 웹 페이지를 크롤링하고, 텍스트를 분할하여 벡터 스토어에 저장합니다. 이 벡터 스토어는 나중에 정보 검색을 위한 데이터베이스 역할을 합니다.필요한 라이브러리 임포트langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    from langchain_community.document_loaders import WebBaseLoader
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
  데이터 로드 및 분할, 벡터 스토어 생성langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    # 크롤링할 웹 페이지 URL 목록
urls = [
    "https://finance.naver.com/",
    "https://finance.yahoo.com/",
    "https://finance.daum.net/",
]

# 각 URL에서 문서 로드
docs = [WebBaseLoader(url).load() for url in urls]
docs_list = [item for sublist in docs for item in sublist]

# 문서 분할 설정
text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
    chunk_size=300, chunk_overlap=50
)
doc_splits = text_splitter.split_documents(docs_list)

# 벡터 스토어에 문서 추가
vectorstore = Chroma.from_documents(
    documents=doc_splits,
    collection_name="rag-chroma",
    embedding=OpenAIEmbeddings(),
)
retriever = vectorstore.as_retriever()
  3단계: 에이전트 상태(State) 및 도구(Tool) 정의LangGraph 워크플로우의 각 단계에서 공유될 상태를 정의하고, 벡터 스토어에서 문서를 검색하는 도구를 생성합니다.에이전트 상태 정의: AgentState는 워크플로우 전반에 걸쳐 메시지(채팅 기록)를 관리하는 역할을 합니다.langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    from typing import Annotated, Sequence, TypedDict
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages

# 에이전트 상태를 나타내는 데이터 구조 정의
class AgentState(TypedDict):
    # add_messages는 상태가 업데이트될 때 메시지를 "추가"하라고 지시합니다.
    # 기본값은 덮어쓰기입니다.
    messages: Annotated[Sequence[BaseMessage], add_messages]
  검색 도구 생성: create_retriever_tool을 사용하여 앞에서 만든 retriever를 에이전트가 사용할 수 있는 도구로 만듭니다.langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    from langchain.tools.retriever import create_retriever_tool

# 검색 도구 생성
retriever_tool = create_retriever_tool(
    retriever,
    "retrieve_blog_posts",
    "네이버, 야후, 다음의 금융 관련 정보를 검색하고 반환합니다.",
)

tools = [retriever_tool]
  4단계: 에이전트의 행동(노드 함수) 정의워크플로우를 구성하는 각 노드(Node)의 행동을 함수로 정의합니다. 각 함수는 state를 입력받아 처리 후, 업데이트된 state를 반환합니다.문서 관련성 평가 노드 (grade_documents): 검색된 문서가 질문과 관련이 있는지 평가하여 "generate" 또는 "rewrite"를 반환합니다.langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    from typing import Literal
from langchain_core.prompts import PromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI

# Edges
def grade_documents(state) -> Literal["generate", "rewrite"]:
    """
    검색된 문서가 질문과 관련이 있는지 평가합니다.

    Args:
        state (messages): 현재 상태

    Returns:
        str: 문서의 관련성에 따라 다음 노드 결정 ("generate" 또는 "rewrite")
    """
    print("---문서 관련성 평가---")

    # 데이터 모델 정의
    class grade(BaseModel):
        """관련성 평가를 위한 이진 점수."""
        binary_score: str = Field(description="관련성 점수 'yes' 또는 'no'")

    # LLM 모델 정의
    model = ChatOpenAI(temperature=0, model="gpt-4o-mini", streaming=True)

    # LLM에 데이터 모델 적용
    llm_with_tool = model.with_structured_output(grade)

    prompt = PromptTemplate(
        template="""당신은 사용자 질문에 대한 검색된 문서의 관련성을 평가하는 평가자입니다.
        여기 검색된 문서가 있습니다: \n\n {context} \n\n
        여기 사용자 질문이 있습니다: {question} \n
        문서가 사용자 질문과 관련된 키워드 또는 의미를 포함하면 관련성이 있다고 평가하세요.
        문서가 질문과 관련이 있는지 여부를 나타내기 위해 'yes' 또는 'no'로 이진 점수를 주세요. : """,
        input_variables=["context", "question"],
    )
    
    messages = state["messages"]
    last_message = messages[-1]
    
    question = messages[0].content
    docs = last_message.content
    
    scored_result = llm_with_tool.invoke({"question": question, "context": docs})
    
    score = scored_result.binary_score

    if score == "yes":
        print("---결정: 문서 관련성 있음---")
        return "generate"
    else:
        print("---결정: 문서 관련성 없음---")
        return "rewrite"
  에이전트 노드 (agent): 사용자의 질문에 따라 도구를 호출하여 검색을 수행합니다.langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    def agent(state):
    """
    현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다.
    주어진 질문에 따라 검색 도구를 사용하여 검색을 수행하거나 단순히 종료하기로 결정합니다.
    
    Args:
        state (messages): 현재 상태
        
    Returns:
        dict: 메시지에 에이전트 응답이 추가된 업데이트된 상태
    """
    print("---에이전트 호출---")
    messages = state["messages"]
    # 메시지가 제대로 전달되고 있는지 확인
    # print("에이전트로 전달된 메시지들:",messages)
    model = ChatOpenAI(temperature=0, streaming=True, model="gpt-4o-mini")
    model = model.bind_tools(tools)
    response = model.invoke(messages)
    
    # 응답을 상태에 추가
    return {"messages": [response]}
  질문 재작성 노드 (rewrite): 검색된 문서의 관련성이 낮을 때, 더 나은 검색 결과를 위해 질문을 재작성합니다.langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    from langchain_core.messages import HumanMessage

def rewrite(state):
    """
    질문을 재작성(변형)하여 더 나은 질문을 생성합니다.
    
    Args:
        state (messages): 현재 상태
    
    Returns:
        dict: 재구성된 질문으로 업데이트된 상태
    """
    print("---질문 변형---")
    messages = state["messages"]
    question = messages[0].content

    msg = [
        HumanMessage(
            content=f"""다음 입력을 보고 근본적인 의도나 의미를 파악해보세요.
            초기 질문은 다음과 같습니다:
            \n ------- \n
            {question}
            \n ------- \n
            개선된 질문을 만들어주세요:""",
        )
    ]
    
    # 평가
    model = ChatOpenAI(temperature=0, model="gpt-4o-mini", streaming=True)
    response = model.invoke(msg)
    
    return {"messages": [response]}
  답변 생성 노드 (generate): 관련성 높은 문서를 기반으로 최종 답변을 생성합니다.langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    from langchain_core.output_parsers import StrOutputParser

def generate(state):
    """
    답변 생성
    
    Args:
        state (messages): 현재 상태
    
    Returns:
        dict: 재구성된 질문으로 업데이트된 상태
    """
    print("---생성---")
    messages = state["messages"]
    question = messages[0].content
    last_message = messages[-1]
    
    docs = last_message.content
    
    # 프롬프트
    prompt = hub.pull("rlm/rag-prompt") # LangChain Hub에서 프롬프트 가져오기 (만약 없다면 아래 Template 사용)
    
    # 프롬프트 정의 (Hub 사용이 안될 경우)
    template = """당신은 질문-답변 작업을 위한 어시스턴트입니다.
    아래 제공된 문맥을 사용하여 질문에 답변해주세요.
    답을 모를 경우 '모르겠습니다'라고 말해주세요. 답변은 최대 3문장으로 간결하게 작성하세요.
    
    질문: {question}
    문맥: {context}
    답변:"""
    prompt = PromptTemplate(template=template, input_variables=["context", "question"])

    # LLM
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, streaming=True)
    
    # 체인
    rag_chain = prompt | llm | StrOutputParser()
    
    # 실행
    response = rag_chain.invoke({"context": docs, "question": question})
    return {"messages": [response]}
  5단계: 워크플로우 그래프 생성 및 실행정의한 노드와 상태를 LangGraph를 사용하여 하나의 워크플로우 그래프로 연결합니다.그래프 생성 및 노드 추가langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    from langgraph.graph import END, StateGraph, START
from langgraph.prebuilt import ToolNode

# 워크플로우를 정의합니다.
workflow = StateGraph(AgentState)

# 순환할 노드들을 정의합니다.
workflow.add_node("agent", agent) # 에이전트 노드
retrieve = ToolNode([retriever_tool])
workflow.add_node("retrieve", retrieve) # 검색 도구 노드
workflow.add_node("rewrite", rewrite) # 질문 재작성 노드
workflow.add_node("generate", generate) # 문서가 관련성이 있다고 판단된 후 응답 생성 노드
  엣지(Edge) 및 조건부 엣지(Conditional Edge) 설정langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    # 에이전트 노드를 호출하여 검색을 결정합니다.
workflow.add_edge(START, "agent")

# 검색 여부를 결정합니다.
workflow.add_conditional_edges(
    "agent",
    # 에이전트 결정 평가
    tools_condition,
    {
        # 조건 출력을 그래프 내 노드로 변환, 반환 값: 실행 노드
        "tools": "retrieve",
        END: END,
    },
)

# 검색 후 문서 관련성 평가
workflow.add_conditional_edges(
    "retrieve",
    # 에이전트 결정 평가
    grade_documents,
    {
        # 조건 출력을 그래프 내 노드로 변환, 반환 값: 실행 노드
        "generate": "generate",
        "rewrite": "rewrite",
    },
)
workflow.add_edge("generate", END)
workflow.add_edge("rewrite", "agent")
  그래프 컴파일 및 시각화langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    # 컴파일
graph = workflow.compile()

# 그래프 시각화 (Jupyter 환경에서 실행)
from IPython.display import Image, display
try:
    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))
except Exception:
    pass
  6단계: 그래프 실행 및 결과 확인이제 완성된 그래프를 실행하여 사용자의 질문에 대한 답변 생성 과정을 확인합니다.그래프 실행langGraph-agenticRag.ipynb code Pythondownloadcontent_copyexpand_lessIGNORE_WHEN_COPYING_STARTIGNORE_WHEN_COPYING_END    import pprint

# 그래프를 실행하고 확인합니다.
inputs = {
    "messages": [
        ("user", "agentic rag가 어떤 의미야?"),
    ]
}
for output in graph.stream(inputs):
    for key, value in output.items():
        pprint.pprint(f"노드 '{key}'의 출력 결과:")
    pprint.pprint(value, indent=2, width=80, depth=None)
pprint.pprint("\n---\n")
  출력 결과 확인: 책의 마지막 이미지처럼 각 노드(agent, retrieve, grade_documents, generate 등)의 실행 결과가 순차적으로 출력되는 것을 볼 수 있습니다. 최종적으로 generate 노드에서 생성된 답변을 확인할 수 있습니다.이 단계별 가이드를 따라 코드를 작성하고 실행하면, 책에서 설명하는 Agentic RAG 기반의 지능형 정보 검색 시스템을 직접 구현해볼 수 있습니다. 각 코드 블록은 주피터 노트북의 셀(cell)에 해당하며, 순서대로 실행하면 됩니다.